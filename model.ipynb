{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, pathlib, shutil, random\n",
    "from config import Config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import _pickle as pk\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg  = Config()\n",
    "\n",
    "clfs = {\n",
    "    \"LR\": LogisticRegression(random_state=cfg.RS), # Logistic Regression\n",
    "    \"SVC\": SVC(random_state=cfg.RS), # Support Vector Classification\n",
    "    \"SGD\": SGDClassifier(random_state=cfg.RS), # Stochastic Gradient Descent\n",
    "    \"PERCEPTRON\": Perceptron(random_state=cfg.RS), # Perceptron\n",
    "    \"MLP\": MLPClassifier(random_state=cfg.RS), #Multi-layer Perceptron\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=3),\n",
    "    \"DT\": DecisionTreeClassifier(criterion = 'entropy', random_state = cfg.RS),\n",
    "    \"GNB\": GaussianNB(),\n",
    "    \"RF\": RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = cfg.RS),\n",
    "    \"ADB\": AdaBoostClassifier(n_estimators=100, random_state=cfg.RS)\n",
    "}\n",
    "\n",
    "datasets = [os.path.basename(dataPath) for dataPath \n",
    "            in glob.glob(os.path.join(cfg.ORG_DATA_PATH, \"*.csv\"))]\n",
    "\n",
    "transformations = [\n",
    "    (cfg.MM_ROWS_PATH, cfg.RLT_PER_ROWS), \n",
    "    (cfg.MM_COLS_PATH, cfg.RLT_PER_COLS), \n",
    "    (cfg.UB_DATA_PATH, cfg.RLT_UB_DATA), \n",
    "    (cfg.NE_DATA_PATH, cfg.RLT_NE_DATA)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCurrentTime():\n",
    "    return str(datetime.datetime.now())\n",
    "\n",
    "def fix_parent_path(rootPath):\n",
    "    pathlib.Path(os.path.dirname(rootPath)).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "def save_raw_clf(kind, clf, cfg):\n",
    "    #print(clf)\n",
    "    rawClfPath = os.path.join(cfg.MODEL_CKPOINT, kind + '.pk')\n",
    "    fix_parent_path(rawClfPath)\n",
    "    with open(rawClfPath, 'wb') as fclf:\n",
    "        pk.dump(clf, fclf)\n",
    "\n",
    "def load_raw_clf(kind, cfg):\n",
    "    clf = None\n",
    "    rawClfPath = os.path.join(cfg.MODEL_CKPOINT, kind + '.pk')\n",
    "    with open(rawClfPath, 'rb') as fclf:\n",
    "        clf = pk.load(fclf)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving checkpoints for ML classifiers...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSaving checkpoints for ML classifiers...\\n\")\n",
    "for kind in clfs.keys():\n",
    "    save_raw_clf(kind, clfs[kind], cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filePath):\n",
    "    df = pd.read_csv(filePath, index_col=None)\n",
    "    correct_labels = df.iloc[:,-1]\n",
    "    feature_vectors = df.drop(df.columns[-1], axis=1)\n",
    "    X_all, y_all = feature_vectors.to_numpy(), correct_labels\n",
    "    return X_all, y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(cfg, kind, dataPath):\n",
    "    X_all, y_all = load_dataset(dataPath)\n",
    "    clf = load_raw_clf(kind, cfg)\n",
    "    clf.fit(X_all, y_all)\n",
    "    y_pred = clf.predict(X_all)\n",
    "    accscore = accuracy_score(y_all, y_pred)\n",
    "    return accscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_transformation(cfg, rootPath, kind, dataset):\n",
    "    traDict = {}\n",
    "    for traPath in glob.glob(os.path.join(rootPath, \"*\")):\n",
    "        traKind = traPath.split(os.path.sep)[-1]\n",
    "        traResult = evaluate_model(cfg, kind, os.path.join(traPath, dataset))\n",
    "        traDict[traKind] = traResult\n",
    "    return traDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_as_dict(cfg, kind, dataset, rootPath):\n",
    "    results = {'dataset': dataset}\n",
    "    orgResult = evaluate_model(cfg, kind, os.path.join(cfg.ORG_DATA_PATH, dataset))\n",
    "    results.update({'original': orgResult})\n",
    "    results.update(evaluate_transformation(cfg, rootPath, kind, dataset))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing results on transformations...\n",
      "\n",
      "[2020-04-20 14:17:15.644984] Completed LR for rows_permutation\n",
      "[2020-04-20 14:17:16.355026] Completed LR for cols_permutation\n",
      "[2020-04-20 14:17:16.978836] Completed LR for unbalanced\n",
      "[2020-04-20 14:17:17.777895] Completed LR for nonequivalent\n",
      "[2020-04-20 14:17:19.455908] Completed SVC for rows_permutation\n",
      "[2020-04-20 14:17:20.643970] Completed SVC for cols_permutation\n",
      "[2020-04-20 14:17:21.748970] Completed SVC for unbalanced\n",
      "[2020-04-20 14:17:23.197720] Completed SVC for nonequivalent\n",
      "[2020-04-20 14:17:23.756968] Completed SGD for rows_permutation\n",
      "[2020-04-20 14:17:24.126610] Completed SGD for cols_permutation\n",
      "[2020-04-20 14:17:24.497007] Completed SGD for unbalanced\n",
      "[2020-04-20 14:17:25.146422] Completed SGD for nonequivalent\n",
      "[2020-04-20 14:17:25.678378] Completed PERCEPTRON for rows_permutation\n",
      "[2020-04-20 14:17:26.016519] Completed PERCEPTRON for cols_permutation\n",
      "[2020-04-20 14:17:26.349987] Completed PERCEPTRON for unbalanced\n",
      "[2020-04-20 14:17:26.726336] Completed PERCEPTRON for nonequivalent\n",
      "[2020-04-20 14:17:37.298266] Completed MLP for rows_permutation\n",
      "[2020-04-20 14:17:43.422859] Completed MLP for cols_permutation\n",
      "[2020-04-20 14:17:50.709840] Completed MLP for unbalanced\n",
      "[2020-04-20 14:17:58.991843] Completed MLP for nonequivalent\n",
      "[2020-04-20 14:17:59.932793] Completed KNN for rows_permutation\n",
      "[2020-04-20 14:18:00.753930] Completed KNN for cols_permutation\n",
      "[2020-04-20 14:18:01.651491] Completed KNN for unbalanced\n",
      "[2020-04-20 14:18:02.512122] Completed KNN for nonequivalent\n",
      "[2020-04-20 14:18:03.241325] Completed DT for rows_permutation\n",
      "[2020-04-20 14:18:03.722767] Completed DT for cols_permutation\n",
      "[2020-04-20 14:18:04.189201] Completed DT for unbalanced\n",
      "[2020-04-20 14:18:04.883156] Completed DT for nonequivalent\n",
      "[2020-04-20 14:18:05.322791] Completed GNB for rows_permutation\n",
      "[2020-04-20 14:18:05.610894] Completed GNB for cols_permutation\n",
      "[2020-04-20 14:18:05.931361] Completed GNB for unbalanced\n",
      "[2020-04-20 14:18:06.297792] Completed GNB for nonequivalent\n",
      "[2020-04-20 14:18:07.221255] Completed RF for rows_permutation\n",
      "[2020-04-20 14:18:07.830066] Completed RF for cols_permutation\n",
      "[2020-04-20 14:18:08.493071] Completed RF for unbalanced\n",
      "[2020-04-20 14:18:09.311107] Completed RF for nonequivalent\n",
      "[2020-04-20 14:18:17.777950] Completed ADB for rows_permutation\n",
      "[2020-04-20 14:18:23.650722] Completed ADB for cols_permutation\n",
      "[2020-04-20 14:18:29.590652] Completed ADB for unbalanced\n",
      "[2020-04-20 14:18:36.777928] Completed ADB for nonequivalent\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nComputing results on transformations...\\n\")\n",
    "for kind in clfs.keys():\n",
    "    for traPaths in transformations:\n",
    "        traKind = traPaths[0].split(os.path.sep)[-1]\n",
    "        resultList = []\n",
    "        for dataset in datasets:\n",
    "            curResult = get_result_as_dict(cfg, kind, dataset, traPaths[0])\n",
    "            resultList.append(curResult)\n",
    "        resultPath = os.path.join(traPaths[1], kind + \".csv\")\n",
    "        fix_parent_path(resultPath)\n",
    "        df = pd.DataFrame(resultList)\n",
    "        colOrder = ['dataset' , 'original']\n",
    "        df = df[ colOrder + [c for c in list(df.columns) if c not in colOrder]]\n",
    "        df.to_csv(resultPath, index=False)\n",
    "        print(\"[{}] Completed {} for {}\".format(getCurrentTime(), kind, traKind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
