{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, pathlib, shutil, random\n",
    "from config import Config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import _pickle as pk\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mRS = 42\n",
    "clfs = {\n",
    "    \"LR\": LogisticRegression(random_state=mRS), # Logistic Regression\n",
    "    \"SVC\": SVC(random_state=mRS), # Support Vector Classification\n",
    "    \"SGD\": SGDClassifier(random_state=mRS), # Stochastic Gradient Descent\n",
    "    \"Perceptron\": Perceptron(random_state=mRS), # Perceptron\n",
    "    \"MLP\": MLPClassifier(random_state=mRS), #Multi-layer Perceptron\n",
    "    \"Knn\": KNeighborsClassifier(n_neighbors=3),\n",
    "    \"DT\": DecisionTreeClassifier(criterion = 'entropy', random_state = mRS),\n",
    "    \"GNB\": GaussianNB(),\n",
    "    \"RF\": RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = mRS),\n",
    "    \"ADB\": AdaBoostClassifier(n_estimators=100, random_state=mRS)\n",
    "}\n",
    "cfg  = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCurrentTime():\n",
    "    return str(datetime.datetime.now())\n",
    "\n",
    "def fix_parent_path(rootPath):\n",
    "    pathlib.Path(os.path.dirname(rootPath)).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "def save_raw_clf(kind, clf, cfg):\n",
    "    #print(clf)\n",
    "    rawClfPath = os.path.join(cfg.Checkpoint, kind + '.pk')\n",
    "    fix_parent_path(rawClfPath)\n",
    "    with open(rawClfPath, 'wb') as fclf:\n",
    "        pk.dump(clf, fclf)\n",
    "\n",
    "def load_raw_clf(kind, cfg):\n",
    "    clf = None\n",
    "    rawClfPath = os.path.join(cfg.Checkpoint, kind + '.pk')\n",
    "    with open(rawClfPath, 'rb') as fclf:\n",
    "        clf = pk.load(fclf)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving checkpoints for ML classifiers...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSaving checkpoints for ML classifiers...\\n\")\n",
    "for kind in clfs.keys():\n",
    "    save_raw_clf(kind, clfs[kind], cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filePath):\n",
    "    df = pd.read_csv(filePath, index_col=None)\n",
    "    correct_labels = df.iloc[:,-1]\n",
    "    feature_vectors = df.drop(df.columns[-1], axis=1)\n",
    "    X_all, y_all = feature_vectors.to_numpy(), correct_labels\n",
    "    return X_all, y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(cfg, kind, dataPath):\n",
    "    X_all, y_all = load_dataset(dataPath)\n",
    "    clf = load_raw_clf(kind, cfg)\n",
    "    clf.fit(X_all, y_all)\n",
    "    y_pred = clf.predict(X_all)\n",
    "    accscore = accuracy_score(y_all, y_pred)\n",
    "    return accscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_transformation(cfg, rootPath, kind, dataset):\n",
    "    traDict = {}\n",
    "    for traPath in glob.glob(os.path.join(rootPath, \"*\")):\n",
    "        traKind = traPath.split(os.path.sep)[-1]\n",
    "        traResult = evaluate_model(cfg, kind, os.path.join(traPath, dataset))\n",
    "        traDict[traKind] = traResult\n",
    "    return traDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing results on transformations...\n",
      "\n",
      "[2020-04-16 03:30:49.057695] Completed LR on SE_Process.csv\n",
      "[2020-04-16 03:30:49.062375] Completed LR on Immuno_Therapy.csv\n",
      "[2020-04-16 03:30:49.075167] Completed LR on German_Credit.csv\n",
      "[2020-04-16 03:30:49.082522] Completed LR on Lung_Cancer.csv\n",
      "[2020-04-16 03:30:49.128195] Completed LR on Voice_Rehabilitation.csv\n",
      "[2020-04-16 03:30:49.133317] Completed LR on Breast_Cancer.csv\n",
      "[2020-04-16 03:30:49.268189] Completed SVC on SE_Process.csv\n",
      "[2020-04-16 03:30:49.272803] Completed SVC on Immuno_Therapy.csv\n",
      "[2020-04-16 03:30:49.354368] Completed SVC on German_Credit.csv\n",
      "[2020-04-16 03:30:49.361324] Completed SVC on Lung_Cancer.csv\n",
      "[2020-04-16 03:30:49.397158] Completed SVC on Voice_Rehabilitation.csv\n",
      "[2020-04-16 03:30:49.417926] Completed SVC on Breast_Cancer.csv\n",
      "[2020-04-16 03:30:49.448553] Completed SGD on SE_Process.csv\n",
      "[2020-04-16 03:30:49.452597] Completed SGD on Immuno_Therapy.csv\n",
      "[2020-04-16 03:30:49.464669] Completed SGD on German_Credit.csv\n",
      "[2020-04-16 03:30:49.474370] Completed SGD on Lung_Cancer.csv\n",
      "[2020-04-16 03:30:49.505793] Completed SGD on Voice_Rehabilitation.csv\n",
      "[2020-04-16 03:30:49.511320] Completed SGD on Breast_Cancer.csv\n",
      "[2020-04-16 03:30:49.532848] Completed Perceptron on SE_Process.csv\n",
      "[2020-04-16 03:30:49.536729] Completed Perceptron on Immuno_Therapy.csv\n",
      "[2020-04-16 03:30:49.543781] Completed Perceptron on German_Credit.csv\n",
      "[2020-04-16 03:30:49.551632] Completed Perceptron on Lung_Cancer.csv\n",
      "[2020-04-16 03:30:49.581625] Completed Perceptron on Voice_Rehabilitation.csv\n",
      "[2020-04-16 03:30:49.588602] Completed Perceptron on Breast_Cancer.csv\n",
      "[2020-04-16 03:30:49.787460] Completed MLP on SE_Process.csv\n",
      "[2020-04-16 03:30:49.804262] Completed MLP on Immuno_Therapy.csv\n",
      "[2020-04-16 03:30:50.492482] Completed MLP on German_Credit.csv\n",
      "[2020-04-16 03:30:50.595560] Completed MLP on Lung_Cancer.csv\n",
      "[2020-04-16 03:30:50.842221] Completed MLP on Voice_Rehabilitation.csv\n",
      "[2020-04-16 03:30:51.239093] Completed MLP on Breast_Cancer.csv\n",
      "[2020-04-16 03:30:51.309402] Completed Knn on SE_Process.csv\n",
      "[2020-04-16 03:30:51.319932] Completed Knn on Immuno_Therapy.csv\n",
      "[2020-04-16 03:30:51.371839] Completed Knn on German_Credit.csv\n",
      "[2020-04-16 03:30:51.379394] Completed Knn on Lung_Cancer.csv\n",
      "[2020-04-16 03:30:51.413761] Completed Knn on Voice_Rehabilitation.csv\n",
      "[2020-04-16 03:30:51.455272] Completed Knn on Breast_Cancer.csv\n",
      "[2020-04-16 03:30:51.522150] Completed DT on SE_Process.csv\n",
      "[2020-04-16 03:30:51.526631] Completed DT on Immuno_Therapy.csv\n",
      "[2020-04-16 03:30:51.537926] Completed DT on German_Credit.csv\n",
      "[2020-04-16 03:30:51.547662] Completed DT on Lung_Cancer.csv\n",
      "[2020-04-16 03:30:51.591536] Completed DT on Voice_Rehabilitation.csv\n",
      "[2020-04-16 03:30:51.597247] Completed DT on Breast_Cancer.csv\n",
      "[2020-04-16 03:30:51.627776] Completed GNB on SE_Process.csv\n",
      "[2020-04-16 03:30:51.632287] Completed GNB on Immuno_Therapy.csv\n",
      "[2020-04-16 03:30:51.643001] Completed GNB on German_Credit.csv\n",
      "[2020-04-16 03:30:51.649567] Completed GNB on Lung_Cancer.csv\n",
      "[2020-04-16 03:30:51.679429] Completed GNB on Voice_Rehabilitation.csv\n",
      "[2020-04-16 03:30:51.684061] Completed GNB on Breast_Cancer.csv\n",
      "[2020-04-16 03:30:51.749390] Completed RF on SE_Process.csv\n",
      "[2020-04-16 03:30:51.763703] Completed RF on Immuno_Therapy.csv\n",
      "[2020-04-16 03:30:51.787033] Completed RF on German_Credit.csv\n",
      "[2020-04-16 03:30:51.804007] Completed RF on Lung_Cancer.csv\n",
      "[2020-04-16 03:30:51.845011] Completed RF on Voice_Rehabilitation.csv\n",
      "[2020-04-16 03:30:51.861723] Completed RF on Breast_Cancer.csv\n",
      "[2020-04-16 03:30:52.478488] Completed ADB on SE_Process.csv\n",
      "[2020-04-16 03:30:52.643322] Completed ADB on Immuno_Therapy.csv\n",
      "[2020-04-16 03:30:52.842473] Completed ADB on German_Credit.csv\n",
      "[2020-04-16 03:30:52.959809] Completed ADB on Lung_Cancer.csv\n",
      "[2020-04-16 03:30:53.375023] Completed ADB on Voice_Rehabilitation.csv\n",
      "[2020-04-16 03:30:53.525881] Completed ADB on Breast_Cancer.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nComputing results on transformations...\\n\")\n",
    "datasets = [os.path.basename(dataPath) for dataPath in glob.glob(os.path.join(cfg.ORG_DATA_PATH, \"*.csv\"))]\n",
    "datasets = [d for d in datasets if d not in ['Census_Income.csv', 'Occupancy.csv', 'Communities_Crime.csv']]\n",
    "\n",
    "for kind in clfs.keys():\n",
    "    rowList, colList = [], []\n",
    "    for dataset in datasets:\n",
    "        orgResult = evaluate_model(cfg, kind, os.path.join(cfg.ORG_DATA_PATH, dataset))\n",
    "        \n",
    "        rowDict = {'dataset': dataset}\n",
    "        rowDict.update({'original': orgResult})\n",
    "        rowDict.update(evaluate_transformation(cfg, cfg.MM_ROWS_PATH, kind, dataset))\n",
    "        rowList.append(rowDict)\n",
    "        \n",
    "        colDict = {'dataset': dataset}\n",
    "        colDict.update({'original': orgResult})\n",
    "        colDict.update(evaluate_transformation(cfg, cfg.MM_COLS_PATH, kind, dataset))\n",
    "        colList.append(colDict)\n",
    "        \n",
    "        print(\"[{}] Completed {} on {}\".format(getCurrentTime(), kind, dataset))\n",
    "\n",
    "    rowResultPath = os.path.join(cfg.RLT_TRA_ROWS, kind + \".csv\")\n",
    "    fix_parent_path(rowResultPath)\n",
    "    pd.DataFrame(rowList).to_csv(rowResultPath, index=False)\n",
    "    \n",
    "    colResultPath = os.path.join(cfg.RLT_TRA_COLS, kind + \".csv\")\n",
    "    fix_parent_path(colResultPath)\n",
    "    pd.DataFrame(colList).to_csv(colResultPath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
